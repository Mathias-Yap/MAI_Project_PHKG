{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import pipelines\n",
    "from pipeline import mdb_validated_generation\n",
    "from pipeline.context.context_constructor import context_constructor\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "import traceback\n",
    "def run_validated_pipeline(data: list[dict]):\n",
    "\n",
    "    context_component = context_constructor(construct_vector_store=True, example_queries_file=\"/home/mathiasyap/Code/university/phkg/MAI_Project_PHKG/src/data/question_queries.yaml\")\n",
    "    generate_execute_component = mdb_validated_generation.MDBValidatedGeneration(model_name = \"gpt-4o-mini\")\n",
    "    val_pipeline  = pipelines.InitialPipeline([context_component,generate_execute_component])\n",
    "    val_pipeline.initialize()\n",
    "    results = []\n",
    "    for entry in notebook_tqdm(data):\n",
    "        try: \n",
    "\n",
    "            result = val_pipeline.run(entry, natural_language_question=entry[\"natural_language_question\"],\n",
    "                                                              sparql_is_path=False)\n",
    "            # print(\"LLM Result with context:\", result_llm_with_context['query'])\n",
    "\n",
    "            results.append(result)\n",
    "        except Exception as ex:\n",
    "            traceback.print_exc()\n",
    "\n",
    "        finally:\n",
    "            try:\n",
    "                val_pipeline.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error while closing pipeline: {e}\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bb016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_example': 'SELECT ?patient WHERE {\\n  ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\\n  ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\\n  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>\\n         <https://www.biomedit.ch/rdf/sphn-schema/sphn/icd#I427> .\\n}\\n', 'question_example': 'Which patients have been diagnosed with I427?', 'question_template': 'Which patients have been diagnosed with {Diagnosis}', 'QuestionNumber': 1, 'query_template': 'SELECT ?patient WHERE {\\n  ?patient sphn:hasDiagnosis ?diag .\\n  ?diag sphn:hasCode ?code .\\n  ?code sphn:hasValue Â§DiagnosisÂ§ .\\n}\\n'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "yaml_file = \"/home/mathiasyap/Code/university/phkg/MAI_Project_PHKG/src/data/question_queries.yaml\"\n",
    "with open(yaml_file, 'r') as file:\n",
    "    question_templates = yaml.safe_load(file)\n",
    "print(question_templates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfda009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mdb:latest']\n",
      "['docker-aseprite:latest']\n",
      "['ghcr.io/avantlab/avantgraph:openaire-transport']\n",
      "['ghcr.io/avantlab/avantgraph:openaire-energy']\n",
      "['ghcr.io/avantlab/avantgraph:openaire-neuro']\n",
      "['ghcr.io/avantlab/avantgraph:openaire-cancer']\n",
      "['hello-world:latest']\n",
      "['ghcr.io/avantlab/avantgraph:ckg']\n",
      "['ghcr.io/avantlab/avantgraph:release-2024-01-31']\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example {i} {'query_example': 'SELECT ?patient WHERE {\\n  ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\\n  ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\\n  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>\\n         <https://www.biomedit.ch/rdf/sphn-schema/sphn/icd#I427> .\\n}\\n', 'question_example': 'Which patients have been diagnosed with I427?', 'question_template': 'Which patients have been diagnosed with {Diagnosis}', 'QuestionNumber': 1, 'query_template': 'SELECT ?patient WHERE {\\n  ?patient sphn:hasDiagnosis ?diag .\\n  ?diag sphn:hasCode ?code .\\n  ?code sphn:hasValue Â§DiagnosisÂ§ .\\n}\\n', 'question_placeholders': ['DIAGNOSIS'], 'query_placeholders': [], 'score': np.float32(169.05746)}\n",
      "example {i} {'query_example': 'SELECT ?patient WHERE {\\n  ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasSubjectPseudoIdentifier> ?patient .\\n  ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDrug> ?drug .\\n  ?drug <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\\n  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasValue> \"M01AE01\"\\n}\\n', 'question_example': 'Which patients have taken M01AE01?', 'question_template': 'Which patients have taken {DRUG}?', 'QuestionNumber': 21, 'query_template': 'SELECT ?patient WHERE {\\n  ?presc sphn:hasSubjectPseudoIdentifier ?patient .\\n  ?presc sphn:hasDrug ?drug .\\n  ?drug sphn:hasCode ?code .\\n  ?code sphn:hasValue Â§DrugÂ§\\n}\\n', 'question_placeholders': ['DRUG'], 'query_placeholders': [], 'score': np.float32(212.89188)}\n",
      "example {i} {'query_example': 'SELECT (COUNT(*) AS ?numPatients) WHERE {\\n  {\\n    SELECT DISTINCT ?patient WHERE {\\n      ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\\n      ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\\n      ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>\\n             <https://www.biomedit.ch/rdf/sphn-schema/sphn/icd#I422> .\\n    }\\n  }\\n}\\n', 'question_example': 'How many patients are there who have been diagnosed with I422?', 'QuestionNumber': 22, 'question_template': 'How many patients are there who have been diagnosed with {Diagnosis}?', 'query_template': 'SELECT (COUNT(DISTINCT ?patient) AS ?numPatients) WHERE {\\n  ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\\n  ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\\n  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> Â§DiagnosisÂ§ .\\n}\\n', 'question_placeholders': ['DIAGNOSIS'], 'query_placeholders': [], 'score': np.float32(222.23279)}\n",
      "examples in LLM: Example 0:\n",
      "Question: Which patients have been diagnosed with I427?\n",
      "Relevant Classes: ['https://www.biomedit.ch/rdf/sphn-schema/sphn/SubjectPseudoIdentifier', 'https://www.biomedit.ch/rdf/sphn-schema/sphn/DrugPrescription']\n",
      "Answer Example 0: SELECT ?patient WHERE {\n",
      "  ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\n",
      "  ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\n",
      "  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>\n",
      "         <https://www.biomedit.ch/rdf/sphn-schema/sphn/icd#I427> .\n",
      "}\n",
      "\n",
      "\n",
      "Example 1:\n",
      "Question: Which patients have taken M01AE01?\n",
      "Relevant Classes: ['https://www.biomedit.ch/rdf/sphn-schema/sphn/SubjectPseudoIdentifier']\n",
      "Answer Example 1: SELECT ?patient WHERE {\n",
      "  ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasSubjectPseudoIdentifier> ?patient .\n",
      "  ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDrug> ?drug .\n",
      "  ?drug <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\n",
      "  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasValue> \"M01AE01\"\n",
      "}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Question: How many patients are there who have been diagnosed with I422?\n",
      "Relevant Classes: ['https://www.biomedit.ch/rdf/sphn-schema/sphn/SubjectPseudoIdentifier', 'https://www.biomedit.ch/rdf/sphn-schema/sphn/DrugPrescription']\n",
      "Answer Example 2: SELECT (COUNT(*) AS ?numPatients) WHERE {\n",
      "  {\n",
      "    SELECT DISTINCT ?patient WHERE {\n",
      "      ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\n",
      "      ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\n",
      "      ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>\n",
      "             <https://www.biomedit.ch/rdf/sphn-schema/sphn/icd#I422> .\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "prompt filled in: \n",
      "Task: Generate a SPARQL SELECT statement for querying a graph database.\n",
      "\n",
      "Instructions:\n",
      "The SPARQL SELECT statement should answer the user question by filling in the provided query templates.\n",
      "Use the ontology terminology to ensure the query is executable on the graph database.\n",
      "Use the question mentioned ontology classes to guide the selection of the appropriate query template.\n",
      "\n",
      "--- Ontology ---\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix sphn: <https://www.biomedit.ch/rdf/sphn-schema/sphn/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "sphn:hasActiveIngredient a owl:ObjectProperty ;\n",
      "    rdfs:label \"has Active Ingredient\" ;\n",
      "    rdfs:comment \"Active component of the concept.\" ;\n",
      "    rdfs:domain sphn:Drug ;\n",
      "    rdfs:range sphn:Substance .\n",
      "\n",
      "sphn:hasCode a owl:ObjectProperty ;\n",
      "    rdfs:label \"has Code\" ;\n",
      "    rdfs:comment \"Coded information specifying the concept.\" ;\n",
      "    rdfs:domain sphn:Diagnosis,\n",
      "        sphn:LabResult,\n",
      "        sphn:MedicalProcedure,\n",
      "        sphn:Substance ;\n",
      "    rdfs:range sphn:Code .\n",
      "\n",
      "sphn:hasCodingSystemAndVersion a owl:DatatypeProperty ;\n",
      "    rdfs:label \"has Coding System and Version\" ;\n",
      "    rdfs:comment \"Name and version of the coding system.\" ;\n",
      "    rdfs:domain sphn:Code ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "sphn:hasDrug a owl:ObjectProperty ;\n",
      "    rdfs:label \"has Drug\" ;\n",
      "    rdfs:comment \"Medication associated to the concept.\" ;\n",
      "    rdfs:domain sphn:DrugPrescription ;\n",
      "    rdfs:range sphn:Drug .\n",
      "\n",
      "sphn:hasLabTest a owl:ObjectProperty ;\n",
      "    rdfs:label \"has Lab Test\" ;\n",
      "    rdfs:comment \"Lab test associated to the concept.\" ;\n",
      "    rdfs:domain sphn:LabTestEvent ;\n",
      "    rdfs:range sphn:LabResult .\n",
      "\n",
      "sphn:hasSubjectPseudoIdentifier a owl:ObjectProperty ;\n",
      "    rdfs:label \"has Subject Pseudo Identifier\" ;\n",
      "    rdfs:domain sphn:Diagnosis,\n",
      "        sphn:DrugPrescription,\n",
      "        sphn:LabTestEvent,\n",
      "        sphn:MedicalProcedure ;\n",
      "    rdfs:range sphn:SubjectPseudoIdentifier .\n",
      "\n",
      "sphn:SubjectPseudoIdentifier a owl:Class ;\n",
      "    rdfs:label \"Patient Identifier\" ;\n",
      "    rdfs:comment \"A coded unique identifier assigned by a data provider for a specific project to conceal the identity of an individual.\" .\n",
      "\n",
      "sphn:Code a owl:Class ;\n",
      "    rdfs:label \"Code\" ;\n",
      "    rdfs:comment \"Symbols and/or expressions defined in a coding system.\" .\n",
      "\n",
      "sphn:Diagnosis a owl:Class ;\n",
      "    rdfs:label \"Diagnosis\" ;\n",
      "    rdfs:comment \"Determination of the presence of a disease, condition, or injury from expressed signs and symptoms and assessments such as physical examination, laboratory test, or the like.\" .\n",
      "\n",
      "sphn:Drug a owl:Class ;\n",
      "    rdfs:label \"Drug\" ;\n",
      "    rdfs:comment \"Any substance with the intent to prevent, diagnose, treat, or relieve symptoms of a disease or abnormal condition.\" .\n",
      "\n",
      "sphn:DrugPrescription a owl:Class ;\n",
      "    rdfs:label \"Drug Prescription\" ;\n",
      "    rdfs:comment \"Plan that defines at which frequency a drug should be administered to a patient with a given quantity; at every frequency time point a drug administration event should occur.\" .\n",
      "\n",
      "sphn:LabResult a owl:Class ;\n",
      "    rdfs:label \"Lab Result\" ;\n",
      "    rdfs:comment \"Outcome, value, or information which gives insight about a laboratory test.\" .\n",
      "\n",
      "sphn:LabTestEvent a owl:Class ;\n",
      "    rdfs:label \"Lab Test Event\" ;\n",
      "    rdfs:comment \"Occurrence in which one or multiple laboratory tests are performed on a biological specimen at a given time.\" .\n",
      "\n",
      "sphn:MedicalProcedure a owl:Class ;\n",
      "    rdfs:label \"Medical Procedure\" ;\n",
      "    rdfs:comment \"Invasive or non-invasive intervention performed for, with or on behalf of an individual whose purpose is to assess, improve, maintain, promote or modify health, functioning or health conditions.\" .\n",
      "\n",
      "sphn:Substance a owl:Class ;\n",
      "    rdfs:label \"Substance\" ;\n",
      "    rdfs:comment \"Any matter of defined composition that has discrete existence, whose origin may be biological, mineral or chemical.\" .\n",
      "\n",
      "\n",
      "\n",
      "--- Templates ---\n",
      "Template 0:\n",
      "Template Question: Which patients have been diagnosed with {Diagnosis}\n",
      "Template Query: SELECT ?patient WHERE {\n",
      "  ?patient sphn:hasDiagnosis ?diag .\n",
      "  ?diag sphn:hasCode ?code .\n",
      "  ?code sphn:hasValue Â§DiagnosisÂ§ .\n",
      "}\n",
      "\n",
      "\n",
      "Template 1:\n",
      "Template Question: Which patients have taken {DRUG}?\n",
      "Template Query: SELECT ?patient WHERE {\n",
      "  ?presc sphn:hasSubjectPseudoIdentifier ?patient .\n",
      "  ?presc sphn:hasDrug ?drug .\n",
      "  ?drug sphn:hasCode ?code .\n",
      "  ?code sphn:hasValue Â§DrugÂ§\n",
      "}\n",
      "\n",
      "\n",
      "Template 2:\n",
      "Template Question: How many patients are there who have been diagnosed with {Diagnosis}?\n",
      "Template Query: SELECT (COUNT(DISTINCT ?patient) AS ?numPatients) WHERE {\n",
      "  ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\n",
      "  ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\n",
      "  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> Â§DiagnosisÂ§ .\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- Examples ---\n",
      "Example 0:\n",
      "Question: Which patients have been diagnosed with I427?\n",
      "Relevant Classes: ['https://www.biomedit.ch/rdf/sphn-schema/sphn/SubjectPseudoIdentifier', 'https://www.biomedit.ch/rdf/sphn-schema/sphn/DrugPrescription']\n",
      "Answer Example 0: SELECT ?patient WHERE {\n",
      "  ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\n",
      "  ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\n",
      "  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>\n",
      "         <https://www.biomedit.ch/rdf/sphn-schema/sphn/icd#I427> .\n",
      "}\n",
      "\n",
      "\n",
      "Example 1:\n",
      "Question: Which patients have taken M01AE01?\n",
      "Relevant Classes: ['https://www.biomedit.ch/rdf/sphn-schema/sphn/SubjectPseudoIdentifier']\n",
      "Answer Example 1: SELECT ?patient WHERE {\n",
      "  ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasSubjectPseudoIdentifier> ?patient .\n",
      "  ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDrug> ?drug .\n",
      "  ?drug <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\n",
      "  ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasValue> \"M01AE01\"\n",
      "}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Question: How many patients are there who have been diagnosed with I422?\n",
      "Relevant Classes: ['https://www.biomedit.ch/rdf/sphn-schema/sphn/SubjectPseudoIdentifier', 'https://www.biomedit.ch/rdf/sphn-schema/sphn/DrugPrescription']\n",
      "Answer Example 2: SELECT (COUNT(*) AS ?numPatients) WHERE {\n",
      "  {\n",
      "    SELECT DISTINCT ?patient WHERE {\n",
      "      ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag .\n",
      "      ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code .\n",
      "      ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>\n",
      "             <https://www.biomedit.ch/rdf/sphn-schema/sphn/icd#I422> .\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- Notes ---\n",
      "Be as concise as possible.\n",
      "Do not include any explanations or apologies in your responses.\n",
      "Do not include any text except for the SPARQL query generated.\n",
      "\n",
      "--- User Question ---\n",
      "The user question is:\n",
      "Which patients have been diagnosed with I600?\n",
      "\n",
      "The question mentioned ontology classes are:\n",
      "['https://www.biomedit.ch/rdf/sphn-schema/sphn/SubjectPseudoIdentifier']\n",
      "\n",
      "The answered SPARQL query is:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  0%|          | 0/1 [01:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m entry2[\u001b[33m\"\u001b[39m\u001b[33mnatural_language_question\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mWhich patients have been diagnosed with I600?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m data.append(entry2)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m data_try = \u001b[43mrun_validated_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mrun_validated_pipeline\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m notebook_tqdm(data):\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         result = \u001b[43mval_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnatural_language_question\u001b[49m\u001b[43m=\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnatural_language_question\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                                                          \u001b[49m\u001b[43msparql_is_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# print(\"LLM Result with context:\", result_llm_with_context['query'])\u001b[39;00m\n\u001b[32m     20\u001b[39m         results.append(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/university/phkg/MAI_Project_PHKG/src/pipeline/pipelines.py:25\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, initial_data, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâ–¶ Running step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m data = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m end_time = time.time()\n\u001b[32m     27\u001b[39m duration = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/university/phkg/MAI_Project_PHKG/src/pipeline/mdb_validated_generation.py:29\u001b[39m, in \u001b[36mMDBValidatedGeneration.run\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Get the initial query from the LLM generator\u001b[39;00m\n\u001b[32m     28\u001b[39m start_init_query_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33minitial_query_time\u001b[39m\u001b[33m\"\u001b[39m] = time.time() - start_init_query_time \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Loop until a valid query is generated or max tries are reached\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/university/phkg/MAI_Project_PHKG/src/pipeline/simple_llm_query_generator.py:194\u001b[39m, in \u001b[36mSimpleLLMQueryGenerator.run\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m    193\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ§  Attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.tries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Prompting LLM...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m raw_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_model_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    196\u001b[39m     query = \u001b[38;5;28mself\u001b[39m.extract_sparql(raw_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/university/phkg/MAI_Project_PHKG/src/pipeline/llm/llm_pipeline.py:25\u001b[39m, in \u001b[36mModelPipeline.generate\u001b[39m\u001b[34m(self, prompt, system_prompt)\u001b[39m\n\u001b[32m     18\u001b[39m chat.add_user_message(prompt)\n\u001b[32m     19\u001b[39m pipeline = transformers.pipeline(\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m     22\u001b[39m     torch_dtype=torch.bfloat16,\n\u001b[32m     23\u001b[39m     device=\u001b[32m0\u001b[39m,\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/pipelines/text_generation.py:295\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    297\u001b[39m         chats = (Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs)  \u001b[38;5;66;03m# ðŸˆ ðŸˆ ðŸˆ\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/pipelines/base.py:1431\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1424\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1425\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m         )\n\u001b[32m   1429\u001b[39m     )\n\u001b[32m   1430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/pipelines/base.py:1438\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1437\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1438\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/pipelines/base.py:1338\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1337\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/pipelines/text_generation.py:400\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    398\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[32m    403\u001b[39m     generated_sequence = output.sequences\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/generation/utils.py:3560\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3560\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3562\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3563\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3564\u001b[39m     outputs,\n\u001b[32m   3565\u001b[39m     model_kwargs,\n\u001b[32m   3566\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3567\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:688\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m output_hidden_states = (\n\u001b[32m    684\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:453\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    451\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:324\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    322\u001b[39m residual = hidden_states\n\u001b[32m    323\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    327\u001b[39m outputs = (hidden_states,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:162\u001b[39m, in \u001b[36mLlamaMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     down_proj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "data =[]\n",
    "entry1 = {}\n",
    "entry1[\"natural_language_question\"] = \"Which patients have been diagnosed with I521?\"\n",
    "entry2 = {}\n",
    "entry2[\"natural_language_question\"] = \"Which patients have been diagnosed with I600?\"\n",
    "data.append(entry2)\n",
    "data_try = run_validated_pipeline(\n",
    "        data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098caa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdata_try\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "data_try[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which patients have been diagnosed with I600?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_try[0]['natural_language_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2d637",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1054484281.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdata_try[0][]\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_try[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9845493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SELECT?patient WHERE {?patient '\n",
      " '<https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis>?diag.?diag '\n",
      " '<https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode>?code.?code '\n",
      " '<https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>?diag. }')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(data_try[0]['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21faa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'natural_language_question': 'Which patients have been diagnosed with I521?', 'prompt_templates': 'Template 0:\\nTemplate Question: Which patients have been diagnosed with Â§DiagnosisÂ§?\\nTemplate Query: SELECT ?patient WHERE { ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag . ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code . ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> Â§DiagnosisÂ§ . }\\n\\nTemplate 1:\\nTemplate Question: Which patients have been diagnosed with Â§Diagnosis1Â§ or Â§Diagnosis2Â§\\nTemplate Query: SELECT ?patient WHERE { { ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag . ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code . ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> Â§Diagnosis1Â§ .} UNION { ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag . ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code . ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> Â§Diagnosis2Â§ . } }\\n\\nTemplate 2:\\nTemplate Question: Which patients have taken Â§DrugÂ§?\\nTemplate Query: ?patient WHERE { ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasSubjectPseudoIdentifier> ?patient . ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDrug> ?drug . ?drug <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code . ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> Â§DrugÂ§ }\\n\\n', 'prompt_examples': 'Example0:\\nQuestion: Which patients have been diagnosed with I428?\\nAnswer Example 0: SELECT ?patient WHERE { ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag . ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code . ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> \"I428\" . }\\n\\nExample1:\\nQuestion: Which patients have been diagnosed with I739 or I452\\nAnswer Example 1: SELECT ?patient WHERE { { ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag . ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code . ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> \"I739\" .} UNION { ?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis> ?diag . ?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code . ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> \"I452\" . } }\\n\\nExample2:\\nQuestion: Which patients have taken M01AE01?\\nAnswer Example 2: ?patient WHERE { ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasSubjectPseudoIdentifier> ?patient . ?presc <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDrug> ?drug . ?drug <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode> ?code . ?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue> \"M01AE01\" }\\n\\n', 'relevant_classes': ['https://www.biomedit.ch/rdf/sphn-schema/sphn/SubjectPseudoIdentifier'], 'validation_time': [], 'valid_query': True, 'query': 'SELECT?patient WHERE {?patient <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasDiagnosis>?diag.?diag <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCode>?code.?code <https://www.biomedit.ch/rdf/sphn-schema/sphn/hasCodeValue>?diag. }', 'attempts': 0, 'initial_query_time': 22.193639755249023, 'result': [], 'final_query_execution_time': 0.005574464797973633, 'total_time': 27.834004878997803}]\n"
     ]
    }
   ],
   "source": [
    "print(data_try)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
